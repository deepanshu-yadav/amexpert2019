{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.read_csv('data/train_AUpWtIz/customer_transaction_data.csv')\n",
    "item_df = pd.read_csv('data/train_AUpWtIz/item_data.csv' )\n",
    "campaign_df = pd.read_csv('data/train_AUpWtIz/campaign_data.csv' )\n",
    "main_df = pd.read_csv('data/train_AUpWtIz/train.csv' )\n",
    "coupon_item_df = pd.read_csv('data/train_AUpWtIz/coupon_item_mapping.csv')\n",
    "customer_details_df = pd.read_csv('data/train_AUpWtIz/customer_demographics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Established</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Established</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  brand   brand_type       category\n",
       "0        1      1  Established        Grocery\n",
       "1        2      1  Established  Miscellaneous"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>other_discount</th>\n",
       "      <th>coupon_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>26830</td>\n",
       "      <td>1</td>\n",
       "      <td>35.26</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>54253</td>\n",
       "      <td>1</td>\n",
       "      <td>53.43</td>\n",
       "      <td>-13.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>31962</td>\n",
       "      <td>1</td>\n",
       "      <td>106.50</td>\n",
       "      <td>-14.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  customer_id  item_id  quantity  selling_price  other_discount  \\\n",
       "0  2012-01-02         1501    26830         1          35.26          -10.69   \n",
       "1  2012-01-02         1501    54253         1          53.43          -13.89   \n",
       "2  2012-01-02         1501    31962         1         106.50          -14.25   \n",
       "\n",
       "   coupon_discount  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_unique = item_df.item_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 74064, 74065, 74066])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74066"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(it_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74066"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 7 columns):\n",
      "customer_id       760 non-null int64\n",
      "age_range         760 non-null object\n",
      "marital_status    431 non-null object\n",
      "rented            760 non-null int64\n",
      "family_size       760 non-null object\n",
      "no_of_children    222 non-null object\n",
      "income_bracket    760 non-null int64\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 41.6+ KB\n"
     ]
    }
   ],
   "source": [
    "customer_details_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_details_df[\"age_range\"] = customer_details_df[\"age_range\"].astype('category')\n",
    "\n",
    "# customer_details_df[\"age_range\"] = customer_details_df[\"age_range\"].cat.codes\n",
    "\n",
    "def convert_into_categorical(df , exclude_list=None):   \n",
    "    if exclude_list != None:\n",
    "        col_list = df.columns\n",
    "        final_list = [x for x in col_list if x not in exclude_list]\n",
    "    else:\n",
    "        final_list = df.columns\n",
    "    for col in final_list:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype('category')\n",
    "            df[col] = df[col].cat.codes\n",
    "\n",
    "convert_into_categorical(customer_details_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rented</th>\n",
       "      <th>family_size</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  age_range  marital_status  rented  family_size  \\\n",
       "0            1          5               0       0            1   \n",
       "1            6          3               0       0            1   \n",
       "2            7          1              -1       0            2   \n",
       "3            8          1              -1       0            3   \n",
       "4           10          3               1       0            0   \n",
       "\n",
       "   no_of_children  income_bracket  \n",
       "0              -1               4  \n",
       "1              -1               5  \n",
       "2               0               3  \n",
       "3               1               6  \n",
       "4              -1               5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_df.info()\n",
    "convert_into_categorical(item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  brand  brand_type  category\n",
       "0        1      1           0         6\n",
       "1        2      1           0         8\n",
       "2        3     56           1         1\n",
       "3        4     56           1         6\n",
       "4        5     56           1         6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_into_categorical( campaign_df , ['start_date' , 'end_date' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>21/10/13</td>\n",
       "      <td>20/12/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>21/10/13</td>\n",
       "      <td>22/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>07/09/13</td>\n",
       "      <td>16/11/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id  campaign_type start_date  end_date\n",
       "0           24              1   21/10/13  20/12/13\n",
       "1           25              1   21/10/13  22/11/13\n",
       "2           20              1   07/09/13  16/11/13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(transaction_df.customer_id.unique()) == len(transaction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324566\n",
      "1321650\n"
     ]
    }
   ],
   "source": [
    "print( len(transaction_df) )\n",
    "transaction_df =  transaction_df.drop_duplicates()\n",
    "print(len(transaction_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78369\n",
      "78369\n"
     ]
    }
   ],
   "source": [
    "print(len(main_df))\n",
    "main_df = main_df.drop_duplicates()\n",
    "print( len(main_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "760\n"
     ]
    }
   ],
   "source": [
    "print(len(customer_details_df))\n",
    "customer_details_df = customer_details_df.drop_duplicates()\n",
    "print( len(customer_details_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92663\n",
      "92663\n"
     ]
    }
   ],
   "source": [
    "print(len(coupon_item_df))\n",
    "coupon_item_df = coupon_item_df.drop_duplicates()\n",
    "print( len(coupon_item_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74066\n",
      "74066\n"
     ]
    }
   ],
   "source": [
    "print(len(item_df))\n",
    "item_df = item_df.drop_duplicates()\n",
    "print( len(item_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(campaign_df))\n",
    "campaign_df = campaign_df.drop_duplicates()\n",
    "print( len(campaign_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "camp_main_merge = pd.merge(  main_df , campaign_df , on = 'campaign_id' , how ='left'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>redemption_status</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19/05/13</td>\n",
       "      <td>05/07/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19/05/13</td>\n",
       "      <td>05/07/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  campaign_id  coupon_id  customer_id  redemption_status  campaign_type  \\\n",
       "0   1           13         27         1053                  0              0   \n",
       "1   2           13        116           48                  0              0   \n",
       "\n",
       "  start_date  end_date  \n",
       "0   19/05/13  05/07/13  \n",
       "1   19/05/13  05/07/13  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camp_main_merge.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " cus_main_camp_merge_df  = pd.merge(  camp_main_merge ,  customer_details_df , on = 'customer_id' , how ='left'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78369\n"
     ]
    }
   ],
   "source": [
    "cus_main_camp_merge_df.head(2)\n",
    "print( len(cus_main_camp_merge_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_item_full = pd.merge(coupon_item_df , item_df , on = 'item_id' , how = 'left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coupon_id  item_id  brand  brand_type  category\n",
       "0        105       37     56           1         6\n",
       "1        107       75     56           1         6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupon_item_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92663 92663\n"
     ]
    }
   ],
   "source": [
    "print( len(coupon_item_full ) ,len(coupon_item_df)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">brand</th>\n",
       "      <th colspan=\"2\" halign=\"left\">brand_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "      <th>nunique</th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "      <th>nunique</th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2084</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coupon_id item_id   brand          brand_type          category         \n",
       "              count nunique <lambda>    nunique <lambda>  nunique <lambda>\n",
       "0         1      39       3     1475          1        0        2        9\n",
       "1         2       2       1     2084          1        0        1        6\n",
       "2         3      17       2      278          1        0        1        6\n",
       "3         4      24       1      544          1        0        1        6\n",
       "4         5       7       1     5357          1        0        1       11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mode_fn = lambda x: pd.Series.mode(x)[0]\n",
    "aggs= ['nunique',mode_fn]\n",
    "coupon_item_agg = coupon_item_full.groupby('coupon_id').agg(  {\n",
    "                                                                'item_id' : 'count',\n",
    "                                                                'brand' : aggs ,\n",
    "                                                                 'brand_type' : aggs,\n",
    "                                                                'category' : aggs\n",
    "} ).reset_index()\n",
    "coupon_item_agg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepanshu/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py:544: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/deepanshu/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:3111: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(cus_main_camp_merge_df , coupon_item_agg , on='coupon_id' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78369"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "﻿# AmExpert 2019 Machine Learning Hackathon\n",
    "## Score\n",
    "- Private LB Rank:  13th\n",
    "- Private LB Score:  0.9273\n",
    "- Public LB Rank: 18th\n",
    "- Public LB Score:  0.9361\n",
    "## Important points for top score achievement\n",
    "\n",
    " 1. Understanding table relationships and performing various merging of the tables\n",
    " 2. Merging customer transaction data inside cross validation instead of before cross validation.\n",
    " 3. Performing Time Series Cross Validation Technique to prevent target leak.\n",
    " 4. Treating categorical columns with huge values as text and generating  tfidf (term frequency inverse document frequency) features while merging.\n",
    " 5. Test Predictions using full train data set with the iterations information retrieved from time series cross validation\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### Label Encoding\n",
    "Label encoding is performed on below categorical data.\n",
    " - _brand_type_ and _category_ columns in `item_data` table \n",
    "  - _marital_status_, _age_range_, _family_size_,   _no_of_children_ in `customer_demographics` table \n",
    " - _campaign_type_ in `campaign_data` table\n",
    "\n",
    "### Date Feature formatting\n",
    "   The following columns that contain date are converted to pandas date time format for further date comparison and filtering.\n",
    "- _date_ column in `customer_transaction_data` table \n",
    "- _start_date_ and _end_date_ columns in `campaign_data` table\n",
    "\n",
    "\n",
    "## Merging Data\n",
    "This competition contains data from multiple tables and hence proper merging of data need to be performed depending upon the type of relationship.\n",
    "\n",
    "#### Understanding Table relationships\n",
    "There are different types of table relationships possible:\n",
    "\n",
    "| Relationship      |Description  |\n",
    "|----------------------|-------------------------------|\n",
    "|`one-to-one`        |Both tables can have only one record on either side of the relationship. Each primary key value relates to only one (or no) record in the related table \n",
    "|`one-to-many`        |The parent table (or primary key table) contains only one record that relates to none, one, or many records in the child table \n",
    "|`many-to-many`        |Each record in both tables can relate to any number of records (or no records) in the other table.\n",
    "\n",
    "The following depicts the type of table relationships in this competition.\n",
    "\n",
    "**one-to-many relationship tables**\n",
    "\n",
    "| Tables|  Key\n",
    "|----------------------|-------------------------------|\n",
    "|`campaign_data` and `train` (or `test`)        |campaign_id\n",
    "|`customer_demographics` and `train` (or `test`)          |customer_id\n",
    "|`item_data`  and `customer_transaction_data`         |item_id\n",
    "|`customer_demographics` and `customer_transaction_data`       |customer_id\n",
    "\n",
    "**many-to-many relationship tables**\n",
    "\n",
    "| Tables|  Key\n",
    "|----------------------|-------------------------------|\n",
    "|`train` (or `test`)   and `customer_transaction_data`          | customer_id\n",
    "|`coupon_item_mapping` and `item_data`        | item_id\n",
    "|`coupon_item_mapping`  and `customer_transaction_data`         |item_id\n",
    "\n",
    "**Multi level relationship**\n",
    "There are also following relationships which goes upto 2 levels.\n",
    "\n",
    " - `train` (or `test`)   ->`coupon_item_mapping` on coupon_id and `coupon_item_mapping` ->`customer_transaction_data` on item_id\n",
    "- `train` (or `test`)   ->`coupon_item_mapping` on coupon_id and `coupon_item_mapping` ->`item_data` on item_id\n",
    "\n",
    "Hence from the above multi-level relationship, it can be seen that there is an indirect `many-to-many` relationship between `train` (or `test`)   and `item_data` tables.\n",
    "\n",
    "**Merging techniques**\n",
    "Separate merging process will be applied for one-to-many and many-to-one relationships. \n",
    "- For `one-to-many`, simple merge of both tables will provide combined features and \n",
    "- for `many-to-many`, aggregation of columns such as mean, min, max etc need to be performed on the table that will be joined.\n",
    "\n",
    "\n",
    "**Merging Process**\n",
    "- Simple merge of `train` (or `test`)   table with `campaign_data` and `customer_demographics` are performed. \n",
    "- Then aggregates of `item_data` is generated from `coupon_item_mapping` parent table using coupon_id  key. All `item_data` columns are categorical, the aggregates performed for the categorical columns are *mode* and *nunique*.\n",
    "- \n",
    "> **Note**: `customer_transaction_data` has been merged only during the cross validation. The reason is that this table contains the redeemed discount amount and other features which are directly related with the target variable redemption_status. If the merge is performed before cross validation, there would be *target leak* from this table.\n",
    "\n",
    "Code: \n",
    "\n",
    "```python\n",
    "def merge_data(data):\n",
    "    \n",
    "    data_unmerged = data.copy()\n",
    "    \n",
    "    #merge data to campaign Data many to 1 on campaign_id key (left join)\n",
    "    campaign_data_merge = pd.merge(data,campaign_data,on='campaign_id',how='left')\n",
    "    #coupon to item_data (many to 1) on item_id key (left join) - call coupon item \n",
    "    coupon_to_item = pd.merge(coupon_item_mapping,item_data,on='item_id',how='left')\n",
    "    \n",
    "    mode_fn = lambda x: pd.Series.mode(x)[0]\n",
    "\n",
    "    aggs= ['nunique',mode_fn]\n",
    "\n",
    "    coupon_to_item_agg = coupon_to_item.groupby(['coupon_id']).agg({'item_id':'count',\n",
    "                                                               'brand':aggs,\n",
    "                                                               'brand_type':aggs,\n",
    "                                                               'category':aggs}).reset_index()\n",
    "    \n",
    "    coupon_to_item_agg.columns = ['coupon_id','coupon_size','brand_nunique','brand_mode',\n",
    "                                 'brand_type_nunique','brand_type_mode',\n",
    "                                 'category_nunique','category_mode']\n",
    "    \n",
    "    #data to coupon item on coupon_id key (left join)\n",
    "    data = pd.merge(campaign_data_merge,coupon_to_item_agg,on='coupon_id',how='left')\n",
    "    #data to customer demographics on customer_id key (left join)\n",
    "    data = pd.merge(data,customer_demographics,on='customer_id',how='left')\n",
    "        \n",
    "    return data    \n",
    "```\n",
    "\n",
    "  ```python\n",
    "train  =  merge_data(train)  \n",
    "print('Train Merge complete')  \n",
    "test  =  merge_data(test)  \n",
    "print('Test Merge complete')\n",
    "```\n",
    "\n",
    "## Cross Validation\n",
    "There are 2 possible approaches of cross validation for this dataset.\n",
    "- To use `StratifiedKFold` cross validation as there is an high class imbalance in the target column \"redemption_status\". (i.e) only less than 1% of data has target value of 1.\n",
    "\n",
    "> **Stratification**: It  is a technique where we rearrange the data in a way that each fold has a good representation of the whole dataset. It forces each fold to have at least m instances of each class. This approach ensures that one class of data is not overrepresented especially when the target variable is unbalanced.\n",
    "\n",
    "- To perform `time series` based validation\n",
    "> **Time series cross-validation**:  In this validation,  validation data is determined based on time period and not random. So specific recent periods would be used as validation set and we consider the previous period’s data as the training set.\n",
    "\n",
    "Without time series based validation, if StratifiedKFold CV was used, then CV score used to shoot upto  0.98 or 0.99 AUC while test score in public leaderboard remains in the range 0.91 and this is because of target leak in CV since it uses the future transactions and hence due to this overfitting, there was not much of improvement in test score in public leaderboard.\n",
    "So, it has been decided to use the **time series based cross validation** .\n",
    "\n",
    "### Time Series Cross Validation\n",
    "- `Walk Forward` (alias Forward chaining) time series CV technique is used to perform validation splits. \n",
    "- Each validation set comprises of 2 campaign periods and remaining previous periods would belong to train set.\n",
    "- There are 5 splits utilized in the code for time series cross validation\n",
    "- Appropriate campaign ids are selected for the validation and train data for each fold\n",
    "\n",
    "Code to specify valid and train set\n",
    "\n",
    "```python\n",
    "import datetime\n",
    "#time series model dates\n",
    "valid_campaign_ids =[]\n",
    "train_campaign_ids =[]\n",
    "\n",
    "valid_campaign_ids +=       [[11,13]]\n",
    "valid_campaign_ids +=       [[10,12]]\n",
    "valid_campaign_ids +=   [[9,8]]\n",
    "valid_campaign_ids += [[6,7]]\n",
    "valid_campaign_ids += [[4,5]]\n",
    "\n",
    "train_campaign_ids +=   [[26,27,28,29,30,1,2,3,4,5,6,7,8,9,10,12]]\n",
    "train_campaign_ids +=   [[26,27,28,29,30,1,2,3,4,5,6,7,8,9]]\n",
    "train_campaign_ids +=   [[26,27,28,29,30,1,2,3,4,5,6,7]]\n",
    "train_campaign_ids +=   [[26,27,28,29,30,1,2,3,4,5]]\n",
    "train_campaign_ids +=   [[26,27,28,29,30,1,2,3]]\n",
    "```\n",
    "### Merging during cross validation\n",
    "As mentioned earlier, merging with `customer_transaction_data` table is performed *only during cross validation* since the transaction data contains the target related information such as coupon_discount etc. \n",
    "\n",
    "#### How transaction data is merged with train / test ?\n",
    "- For train and validation set of each fold, only the `customer_transaction_data` records whose `date` is less than the minimum campaign  `start_date` in the validation set, are utilized for merging and aggregation.  (i.e) only transactions prior to the validation set is considered for model training.\n",
    "- For test set, all records from `customer_transaction_data` is utilized for merging since there were no transaction records once test set campaign period begins\n",
    "\n",
    "Code that sets the filter date\n",
    "```python\n",
    "val_min_start_date = val['start_date'].min()\n",
    "```\n",
    "Code that performs the mentioned filtering before merge\n",
    "```python\n",
    " mask = customer_transaction_data['date'] < filter_date\n",
    " cust_trans_cur = customer_transaction_data[mask]\n",
    " ```\n",
    "\n",
    "#### What data is merged ?\n",
    "\n",
    " - Grouped by **customer_id** in `customer_transaction_data`, aggregates such as min, max, median, mean, standard deviation are generated on columns *quantity, coupon_discount, other_discount and selling_price* and some of the date features and merged with `train` / `test` on customer_id key\n",
    " \n",
    " Code:\n",
    " ```python\n",
    " def merge_trans(data,filter_date):\n",
    "    aggs=['mean','sum','min','max','median','std']\n",
    "    mode_fn = lambda x: pd.Series.mode(x)[0]\n",
    "    \n",
    "    if filter_date is not None:\n",
    "        mask = customer_transaction_data['date'] < filter_date\n",
    "        cust_trans_cur = customer_transaction_data[mask]\n",
    "    else:\n",
    "        cust_trans_cur = customer_transaction_data\n",
    "   \n",
    "\n",
    "    cust_tran_to_item_agg = cust_trans_cur.groupby(['customer_id']).agg({'item_id':['count','nunique',mode_fn],\n",
    "                                                           'date_isweekend':'mean',\n",
    "                                                           'date_month':['mean',mode_fn],\n",
    "                                                           'date_week':['mean',mode_fn],\n",
    "                                                           'date_dayofweek':['mean',mode_fn],\n",
    "                                                           'quantity':aggs,\n",
    "                                                           'other_discount':aggs,\n",
    "                                                           'coupon_discount':aggs,\n",
    "                                                           'selling_price':aggs\n",
    "                                                              }).reset_index()\n",
    "\n",
    "    cust_tran_to_item_agg.columns = ['customer_id','trans_size','item_id_nunique','item_id_mode',\n",
    "                             'date_isweekend_mean','date_month_mean','date_month_mode',\n",
    "                              'date_week_mean','date_week_mode','date_dayofweek_mean','date_dayofweek_mode',\n",
    "                              'quantity_mean','quantity_sum','quantity_min','quantity_max','quantity_median','quantity_std',\n",
    "                              'other_discount_mean','other_discount_sum','other_discount_min','other_discount_max','other_discount_median','other_discount_std',\n",
    "                              'coupon_discount_mean','coupon_discount_sum','coupon_discount_min','coupon_discount_max','coupon_discount_median','coupon_discount_std',\n",
    "                              'selling_price_mean','selling_price_sum','selling_price_min','selling_price_max','selling_price_median','selling_price_std'\n",
    "                             ]\n",
    "    #data to coupon item on coupon_id key (left join)\n",
    "    data = pd.merge(data,cust_tran_to_item_agg,on='customer_id',how='left')\n",
    "    return data\n",
    " ```\n",
    " \n",
    " - Grouped by **customer_id and coupon_id combination**, data from `customer_transaction_data` is merged with `train` / `test` and aggregates such as min, max, median, mean, standard deviation are generated on columns *quantity, coupon_discount, other_discount and selling_price* and some of the date features. Also there is additional filtering performed for this merged data by filtering only the records whose transaction `date` is less than `start_date` of each record merged from `train`\n",
    "\t -  First, `coupon_item_mapping` and `item_data` are merged on \"item_id\" and now the merged data contains both coupon_id and item_id\n",
    "\t - Then `train` / test data is merged with the above merged data so that train / test data contains *one record per item_id and customer_id* combination. The data also contains corresponding coupon_id info.\n",
    "\t - Then the above merged data is further merged with the `customer_transaction_data` on *customer_id and item_id*\n",
    "\t - Then the merged data is grouped `by customer_id and coupon_id` and aggregates are generated on columns *quantity, coupon_discount, other_discount and selling_price*. \n",
    "\t - These aggregates are in-turn merged into `train` / test on customer_id and coupon_id\n",
    "\n",
    "Code: \n",
    "```python\n",
    "def merge_customer_coupon(coupon_to_item,data_prior_merge,\n",
    "                         filter_date):\n",
    "    data_merged = pd.merge(data_prior_merge,coupon_to_item,on='coupon_id',how='left')\n",
    "    data_merged = pd.merge(data_merged,customer_transaction_data,on=['customer_id','item_id'],how='inner')\n",
    " \n",
    "    aggs=['mean','sum','min','max','median','std']\n",
    "    mode_fn = lambda x: pd.Series.mode(x)[0]\n",
    "    \n",
    "    groupbycols = ['customer_id','coupon_id']\n",
    "    \n",
    "    # to filter out records for current validation set\n",
    "    if filter_date is not None:\n",
    "        mask = data_merged['date'] < filter_date\n",
    "        print('before valid date filter:',data_merged.shape)\n",
    "        data_merged = data_merged[mask]\n",
    "        print('after valid date filter:',data_merged.shape)\n",
    "    else:\n",
    "        data_merged = data_merged\n",
    "    \n",
    "    #to filter records that do not belong to current campaign\n",
    "#     print(data_merged.shape)\n",
    "    data_merged = data_merged[data_merged['date'] < data_merged['start_date']]\n",
    "#     print(data_merged.shape)\n",
    "    \n",
    "#     cust_coupon_trans_agg = cust_coupon_trans_agg.filter(lambda x: x['date'] < x['start_date']) \n",
    "    cust_coupon_trans_agg = data_merged.groupby(groupbycols) .agg({'item_id':['count','nunique',mode_fn],\n",
    "                                                               'date_isweekend':'mean',\n",
    "                                                               'date_month':['mean',mode_fn],\n",
    "                                                               'date_week':['mean',mode_fn],\n",
    "                                                               'date_dayofweek':['mean',mode_fn],\n",
    "                                                               'quantity':aggs,\n",
    "                                                               'other_discount':aggs,\n",
    "                                                               'coupon_discount':aggs,\n",
    "                                                               'selling_price':aggs\n",
    "                                                                  }) \\\n",
    "                                                    .reset_index()\n",
    "\n",
    "    cols = ['trans_size','item_id_nunique','item_id_mode',\n",
    "                             'date_isweekend_mean','date_month_mean','date_month_mode',\n",
    "                              'date_week_mean','date_week_mode','date_dayofweek_mean','date_dayofweek_mode',\n",
    "                              'quantity_mean','quantity_sum','quantity_min','quantity_max','quantity_median','quantity_std',\n",
    "                              'other_discount_mean','other_discount_sum','other_discount_min',\n",
    "                                'other_discount_max','other_discount_median','other_discount_std',\n",
    "                              'coupon_discount_mean','coupon_discount_sum','coupon_discount_min',\n",
    "                                'coupon_discount_max','coupon_discount_median','coupon_discount_std',\n",
    "                              'selling_price_mean','selling_price_sum','selling_price_min',\n",
    "                                'selling_price_max','selling_price_median','selling_price_std'\n",
    "                             ]\n",
    "    cols_renamed = ['cust_coupon_' + col for col in cols]\n",
    "#     print(cols_renamed)\n",
    "#     print(cust_coupon_trans_agg.columns)\n",
    "    cust_coupon_trans_agg.columns = groupbycols + cols_renamed\n",
    "    #data to coupon item on coupon_id key (left join)\n",
    "    data_merged = pd.merge(data_prior_merge,cust_coupon_trans_agg,on=groupbycols,how='left')\n",
    "\n",
    "    return data_merged\n",
    "```\n",
    "##### TFIDF Features\n",
    " - Similar to previous merge (i.e.) Grouped by **customer_id and coupon_id combination** and only the columns to generate aggregates are categorical columns: *item_id, brand_type, brand and category*.\n",
    " \n",
    "\t - The mentioned categorical columns need to be utilized to generate beyond simple aggregations inorder to extract maximum information from merging. Hence these categorical columns are treated as **text information** where document represents the various entries of each column within each customer_id and coupon_id combination and all transactions represent the complete possible texts. For e.g. item_id, there can be maximum of 74000+ text possible and list of all item_ids in each customer_id and coupon_id combination row represents a document.\n",
    "\t - Hence **tfidf** (term frequency inverse document frequency) vector features are generated on these categorical data.  The number of features generated depends upon the number of possible values that the corresponding categorical column can have.\n",
    "\t - For fields *brand_type and category*, there are only less than 20 values and hence `full tfidf features` are generated on these columns.\n",
    "\t - For fields *item_id and brand*, there are 74000+ and 5000+ corresponding possible values and generating such huge number of features would be impossible under limited memory constraints and computational time constraints of model training. Hence for these fields, only `top 10 high tfidf features` are determined for each row and hence a total of 20 features would be generated for these fields together.\n",
    "\t \n",
    "Code to generate full tfidf features\n",
    "\n",
    "```python\n",
    "def gen_tfidf_fullfeats(raw_cols_to_gen,data_texts):\n",
    "    tf = TfidfVectorizer(tokenizer=lambda x: x.split(' '))\n",
    "    for col in raw_cols_to_gen:\n",
    "        tfidf_feats = tf.fit_transform(data_texts[col+'_texts'])\n",
    "        tfidf_feats = pd.DataFrame(tfidf_feats .todense(), columns = ['tfidf_dense_'+col+\"_\"+x for x in tf.get_feature_names()])\n",
    "        data_texts = pd.concat([data_texts, X_tfidf], axis=1)\n",
    "    return data_texts\n",
    "```\n",
    "Code to generate top tfidf features\n",
    "```python\n",
    "def get_top_tf_idf_words(response, feature_names,top_n=10):\n",
    "    sorted_data = np.sort(response.data)[:-(top_n+1):-1]\n",
    "    sorted_nzs = np.argsort(response.data)[:-(top_n+1):-1]\n",
    "    return feature_names[response.indices[sorted_nzs]],sorted_data\n",
    "def get_top_fulldata(responses,feature_names,top_n=10):\n",
    "    topdata =[]\n",
    "    topfeatsdata =[]\n",
    "    topvaluesdata =[]\n",
    "    for response in tqdm(responses):\n",
    "        topfeats_topn_size =  np.full(top_n, np.nan) \n",
    "        topvalues_topn_size =  np.full(top_n, np.nan) \n",
    "        topfeats,topvalues = get_top_tf_idf_words(response,feature_names,top_n)\n",
    "        topfeats_topn_size[:len(topfeats)] = topfeats[:]\n",
    "        topvalues_topn_size[:len(topfeats)] = topvalues[:]\n",
    "        topfeatsdata += [topfeats_topn_size]\n",
    "        topvaluesdata += [topvalues_topn_size]\n",
    "        \n",
    "    topfeatsdata = np.array(topfeatsdata)\n",
    "    topvaluesdata = np.array(topvaluesdata)\n",
    "    return topfeatsdata,topvaluesdata\n",
    "def gen_tfidf_topfeats(top_n,raw_cols_to_gen,data_texts):\n",
    "    tf = TfidfVectorizer(tokenizer=lambda x: x.split(' '))\n",
    "\n",
    "    for col in raw_cols_to_gen:\n",
    "        tfidf_feats = tf.fit_transform(data_texts[col+'_texts'])\n",
    "        feature_names = np.array(tf.get_feature_names())\n",
    "        topfeatsdata,topvaluesdata = get_top_fulldata(tfidf_feats ,feature_names,top_n)\n",
    "\n",
    "        #generate dataframe columns\n",
    "        for i in range(topfeatsdata.shape[1]):\n",
    "            namecol = 'tfidf_'+ col + '_name_top_' + str(i+1)\n",
    "            valuecol = 'tfidf_'+ col + '_value_top_' + str(i+1)\n",
    "            data_texts[namecol] = topfeatsdata[:,i]\n",
    "            data_texts[valuecol] = topvaluesdata[:,i]\n",
    "```\n",
    "\n",
    "#### Model parameter tuning\n",
    "\n",
    " - \tSince the generated features are close to around 300, feature_fraction have been tuned to 0.4 (we are intimating the model that approximately 75 features have to be used in each tree ) and it also forces feature selection at tree level which would reduce overfitting.\n",
    " \n",
    "Code that sets feature_fraction of the model:\n",
    "```python\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.4, \n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.75,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         'n_estimators' : 10000,\n",
    "         \"random_state\": 4590}\n",
    "```\n",
    "\n",
    "#### Cross Validation Model Execution\n",
    "Using LightGBM, model training is performed on 5 splits time series cross validation as mentioned earlier and uses the generated merge features (also called as encodings in the code) corresponding to each fold.\n",
    "```python\n",
    "import datetime\n",
    "\n",
    "def runtimeseries(tr_encs,val_encs,test_encs,params,n_splits,fold_feats,\n",
    "                  fit_function,predict_function):\n",
    "    n_splits = 5\n",
    "\n",
    "    model_iterations =[]\n",
    "    fold_importance_df = []\n",
    "    \n",
    "    oof = np.zeros(train.shape[0])\n",
    "    predictions = np.zeros(test.shape[0])\n",
    "    start = time.time()\n",
    "    valid_scores =[]\n",
    "    models =[]\n",
    "\n",
    "        \n",
    "    for fold_ in range(n_splits):\n",
    "        \n",
    "        print('******************* ')\n",
    "        print('fold: ',fold_)\n",
    "        print('valid_campaign_ids: ',valid_campaign_ids[fold_])\n",
    "        print('******************* ')\n",
    "        \n",
    "        cur_features  = fold_feats[fold_].copy()\n",
    "        \n",
    "        tr =  tr_encs[fold_]; val = val_encs[fold_]; test_cur = test_encs[fold_]\n",
    "        y_tr  = tr[targetcol]; y_val = val[targetcol]\n",
    "        tr = tr[cur_features]; val = val[cur_features]; test_cur = test_cur[cur_features]\n",
    "        \n",
    "        print(y_tr.shape)\n",
    "        print(tr.shape)\n",
    "        print(val.shape)\n",
    "        print(y_val.shape)\n",
    "        \n",
    "        print(y_tr.unique())\n",
    "        print(y_val.unique())\n",
    "        \n",
    "        clf = fit_function(tr,val,y_tr,y_val,param)\n",
    "        print('Fit complete')\n",
    "        models += [clf]\n",
    "        \n",
    "        val_preds = predict_function(clf,val)\n",
    "        \n",
    "        val_iterations = params['n_estimators']\n",
    "        if hasattr(clf, 'best_iteration'):\n",
    "               val_iterations = clf.best_iteration\n",
    "\n",
    "        model_iterations+=[val_iterations]\n",
    "\n",
    "        val_score = log_loss(y_val, val_preds)\n",
    "        print('Cur Val Log loss Score:',val_score)\n",
    "        val_score = roc_auc_score(y_val, val_preds)\n",
    "        print('Cur Val AUC Score:',val_score)\n",
    "        valid_scores+=[val_score]\n",
    "        \n",
    "        predictions += predict_function(clf,test_cur) / n_splits\n",
    "        print('Test Pred complete')\n",
    "        \n",
    "\n",
    "        if hasattr(clf, 'feature_importance'):\n",
    "            feature_importance_df = pd.DataFrame()\n",
    "            feature_importance_df[\"Feature\"] = cur_features\n",
    "            feature_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')    \n",
    "            fold_importance_df += [feature_importance_df]\n",
    "\n",
    "    print('valid scores:',valid_scores)\n",
    "    print(\"CV AUC score: \",roc_auc_score(target, oof))\n",
    "    \n",
    "    return models,model_iterations,predictions,oof,fold_importance_df\n",
    "```\n",
    "#### Test Predictions\n",
    "##### Why different approach for test predictions ?\n",
    "- Test Predictions are not generated from cross validation. The reason is that the model was not utilizing the complete set of customer_transaction_data. The cross validation was trained using merged data filtered upto start of validation and also each coupon and customer combination features in train is filtered for corresponding prior transactions (ie. before start of campaign date of each combination). \n",
    "- So, it is decided to utilize the full training set without validation set for test predictions and also get the merged data for training including all transactions (i.e no filter). \n",
    "##### How cross validation results are going to be used in full train model ?\n",
    "- But, it does not mean that the earlier cross validation is not useful. The cross validation is very useful in determining the number of estimators for executing full train model.\n",
    "- There are below possible iteration numbers are used from the 5 splits of time series CV\n",
    "\t- Average number of iterations \n",
    "\t- Maximum number of iterations\n",
    "\t- Minimum number of iterations\n",
    "- 3 different models using full train set is generated using above iterations as estimators for light gbm model and then all these 3 models are blended (ie ensembled) to generate final test predictions. \n",
    "- With this test predictions, the test score in public LB have improved 2 points from 0.91 to 0.93\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
